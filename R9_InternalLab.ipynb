{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R9 Internal Lab Question Notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PHYs6Z84xV8E"},"source":["<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n","\n","Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."]},{"cell_type":"markdown","metadata":{"id":"FbwHYUXhxaqD"},"source":["## Problem Statement\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5QQxgAmWzSye"},"source":["# Samsung Internal SSD Reviews prediction\n","\n","Rating predictions using reviews written by users can be a useful problem statement in E-commerce domain and can be used for recommending similar products that may interest users. The dataset in this problem statement comprises reviews pertaining to Samsung Internal SSD product specifically SAMSUNG 850 EVO 2.5\" 250GB SATA III 3D NAND Internal Solid State Drive (SSD) MZ-75E250B/AM from the NewEgg Store website.  We will build a Natural Language processing model using Glove embeddings which is trained on reviews given by customers that have used the product and try to predict ratings given a new rating.\n","\n","\n","\n","\n","### Objective:\n","Given the reviews provided by customers, can you train a model that accurately predicts the corresponding rating of a review?"]},{"cell_type":"markdown","metadata":{"id":"CI7usguRzeox"},"source":["### Package version\n","\n","- tensorflow==2.3.0\n","- scikit-learn==0.22.2.post1\n","- pandas==1.0.5\n","- numpy==1.18.5\n","- matplotlib==3.2.2\n","- google==2.0.3"]},{"cell_type":"markdown","metadata":{"id":"aiMdVjHRH7NR"},"source":["### Data Dictionary \n","\n","- review_title : The Title for the customer review\n","\n","- overall_review: The whole customer review details\n","\n","- pros: The customer opinion about the good things in this product\n","\n","- cons: The customer opinion about the bad things in this product\n","\n","- ownership_pariod: How long the customer owned this product\n","\n","- date: When the review was written\n","\n","- rating_stars: The product rating from 1 to 5\n","\n","- year: In which year the review was written\n","\n","- month: In which month the review was written\n","\n","- day: In which day the review was written"]},{"cell_type":"markdown","metadata":{"id":"cEn52o8jznJK"},"source":["## Table of Content\n","\n","1. Import Libraries\n","\n","2. Setting options\n","\n","3. Read Data\n","\n","4. Data Analysis and Preparation\n","\n","5. Model Building\n","\n","6. Conclusion and Interpretation\n","\n","7. Food for thought"]},{"cell_type":"markdown","metadata":{"id":"x_Lom6cXzqn7"},"source":["## 1. Import Libraries"]},{"cell_type":"markdown","metadata":{"id":"FZtVstH8zre2"},"source":["Let us start by mounting the drive"]},{"cell_type":"code","metadata":{"id":"jSsg8JHkIh2k","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600158844186,"user_tz":-330,"elapsed":1165,"user":{"displayName":"Mansoor Rahimat Khan","photoUrl":"","userId":"09687443316707549268"}},"outputId":"23310df7-21b5-4d91-e048-43a99c53fdd2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gv-tZoFjz2WD"},"source":["Let us check for the version of installed tensorflow."]},{"cell_type":"code","metadata":{"id":"eiuUVBuDzzn9","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1600158846703,"user_tz":-330,"elapsed":3438,"user":{"displayName":"Mansoor Rahimat Khan","photoUrl":"","userId":"09687443316707549268"}},"outputId":"45de5e8f-ebbc-475b-f8c6-0f4360dea414"},"source":["# used to supress display of warnings\n","import warnings\n","\n","# os is used to provide a way of using operating system dependent functionality\n","# We use it for setting working folder\n","import os\n","\n","# Pandas is used for data manipulation and analysis\n","import pandas as pd \n","\n","# Numpy is used for large, multi-dimensional arrays and matrices, along with mathematical operators on these arrays\n","import numpy as np\n","\n","# Matplotlib is a data visualization library for 2D plots of arrays, built on NumPy arrays \n","# and designed to work with the broader SciPy stack\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from matplotlib import pyplot\n","\n","# Seaborn is based on matplotlib, which aids in drawing attractive and informative statistical graphics.\n","import seaborn as sns\n","import tensorflow \n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fze-aokU0ukH"},"source":["## 2. Setting Options"]},{"cell_type":"code","metadata":{"id":"T3FALggG0xXa"},"source":["# suppress display of warnings\n","warnings.filterwarnings('ignore')\n","\n","# display all dataframe columns\n","pd.options.display.max_columns = None\n","\n","# to set the limit to 3 decimals\n","pd.options.display.float_format = '{:.7f}'.format\n","\n","# display all dataframe rows\n","pd.options.display.max_rows = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZT1P1WdK1vfZ"},"source":["## 3. Read Data"]},{"cell_type":"markdown","metadata":{"id":"NnnvF56gfwav"},"source":["### Read the dataset and check top 5 rows"]},{"cell_type":"code","metadata":{"id":"imj2VbNpf383"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RGluIi5Sf5Rp"},"source":["### Check info of the dataset and write your findings"]},{"cell_type":"code","metadata":{"id":"Pldlew5Mf9gA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rED6DbDBKTjM"},"source":["## 4.  Data Analysis and Preparation"]},{"cell_type":"markdown","metadata":{"id":"7VSqr0Seiy7g"},"source":["### 4.1 Checking missing values\r\n","#### Check for missing values (along with the percentage of null values)"]},{"cell_type":"code","metadata":{"id":"Il4yi7kdmnYQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SB40EGirmVjo"},"source":["### 4.2 Analyzing the target column (Rating_stars)"]},{"cell_type":"markdown","metadata":{"id":"MoRvWVk-is6Y"},"source":["#### Check the value counts of 'rating_stars' and write your comments"]},{"cell_type":"code","metadata":{"id":"LOVFp6Diiy0n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rhr2gnY2lc9h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL_BQlb5mE4O"},"source":["### 4.3 Let's analyze other features like year, month, and day etc.\r\n","#### Check value counts of 'year' and write your observations., Comment on the range of years, frequency of ratings in each year."]},{"cell_type":"code","metadata":{"id":"YAtEigKEmM-Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-pWwPhRmsAz"},"source":["#### Check mean rating for each year and write your findings"]},{"cell_type":"code","metadata":{"id":"sqWWhlLemwG8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"enoYYTDunPsT"},"source":["#### Check value counts of 'month' and write your observations. Comment on the frequency of ratings and discuss if the rating count and mean rating is higher/low on certain months."]},{"cell_type":"code","metadata":{"id":"T0yhG8s1pTZD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lWofLqeJpTtI"},"source":["### 4.4 Combine text features\r\n","#### Drop all the numerical features ['Unnamed: 0','date', 'year', 'month', 'day', 'ownership_pariod'] and ['rating_stars']"]},{"cell_type":"code","metadata":{"id":"8VAMgNJkqn0h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HjRp0SgEqn9Z"},"source":["#### Replace null values (NaN) with blanks"]},{"cell_type":"code","metadata":{"id":"CZr_sR_Tqs1x"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykjSdW1tqs-z"},"source":["#### Join all text items in a row that have a space in between and Add a new column (with the newly created combined reviews) to the dataframe."]},{"cell_type":"code","metadata":{"id":"9fJpSb-ZuSTr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VHzRd1gq1lY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QLnNIq2iJQBn"},"source":["#### Check if there are any null values and drop NaN values if any"]},{"cell_type":"code","metadata":{"id":"QOf3hTpcszKC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qS5NmyvzHMws"},"source":["#### Calculate the length of each review and add it to the dataframe"]},{"cell_type":"code","metadata":{"id":"TdMWM0jBHNzO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8FyfpsW4uNN-"},"source":["#### Check summary stats of the length column"]},{"cell_type":"code","metadata":{"id":"cMEp309bHPSm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JtFWZfZjJSJY"},"source":["### 4.5 Analyzing and preparing the text data\r\n"]},{"cell_type":"markdown","metadata":{"id":"FL0mW8oPJVyq"},"source":["#### Set the max length of each review to 25 since it results in faster training (however, you are free to change this)\r\n","#### Set max_features to 10000 and embedding size to 50"]},{"cell_type":"code","metadata":{"id":"T7Ma4u3kSOD3","executionInfo":{"status":"ok","timestamp":1615275139846,"user_tz":-330,"elapsed":1147,"user":{"displayName":"Garima Rahangdale","photoUrl":"","userId":"12135158262547382026"}}},"source":["max_features = 10000\n","maxlen = 25\n","embedding_size = 50"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qph71mXtJyWM"},"source":["#### Tokenize the cobined text data. You can use the Tokenizer from tensorflow.keras.preprocessing.text. Check the number of samples post tokenization."]},{"cell_type":"code","metadata":{"id":"hvn5Bssu6MoQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXy2gZrkJ0f_"},"source":["#### Pad the above tokenized reviews data save it as independent features. Use max_len for the same."]},{"cell_type":"code","metadata":{"id":"mV-KtcR06OAr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVT7dRRUHsgR"},"source":["#### Check the shape of X (padded tokenized review data) and y (rating_stars) data."]},{"cell_type":"code","metadata":{"id":"SXc3DOi9Hz6O"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A5GlWwKnJ7ie"},"source":["#### Check the total number of words in the dictionary (of tekenizer)"]},{"cell_type":"code","metadata":{"id":"oR0W8MdX6V3A"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKa3eYLDJ_yO"},"source":["### 4.6 Compute the glove embeddings. Use the provided txt file for the same."]},{"cell_type":"markdown","metadata":{"id":"WNwPD9EmIbMt"},"source":["#### Read the glove embeddings from the file provided titled ‘glove.6B.50d.txt’. And save it to a dictotionary having word and corresponding embedding vector."]},{"cell_type":"code","metadata":{"id":"bNd9ZFjuIp3g"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EuolWkfmIqCJ"},"source":["#### Create a weight matrix for words in the training docs"]},{"cell_type":"code","metadata":{"id":"BGHZ0nIaI0Ar"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-DdpiQZ9_Fiq"},"source":["#### Check length of the embedding"]},{"cell_type":"code","metadata":{"id":"8bcs-LtYILlO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xVPf3X5MKGpm"},"source":["### 4.7 Target Feature:- One hot encode the target variable (rating_stars)"]},{"cell_type":"code","metadata":{"id":"7PVDBmkjJC4n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5dqPXETLKN0h"},"source":["### 4.8 Split the data into Train & Test sets"]},{"cell_type":"code","metadata":{"id":"FFJ1oEUmJEEW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhD1a-beKvE7"},"source":["## 5. Model building"]},{"cell_type":"markdown","metadata":{"id":"bRmxklYnKvxk"},"source":["### 5.1 Construct a neural network architecture using embedding and LSTM layers for building the rating prediction model.\r\n","- Use the num_words, embedding_size from the above tokenizer and embeddings respectively\r\n","- Use weights from the above embedding matrix\r\n","- Use input length as the maxlen\r\n","- Add LSTM layers"]},{"cell_type":"code","metadata":{"id":"gSGsebsiNA78"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iN0P-a6X_jAb"},"source":["### 5.2 Compile the model using appropriate loss, optimizer, and accuracy metric"]},{"cell_type":"code","metadata":{"id":"8Kyk9kPxNCMb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tIODqXJK_qrQ"},"source":["### 5.3 Fit the model"]},{"cell_type":"code","metadata":{"id":"fEX-_bd2NDPW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iakHzMFNDsz"},"source":["### 5.4 Predict ratings for test data and check accuracy and confusion matrix"]},{"cell_type":"code","metadata":{"id":"erNFghTpNK-j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"glNaXRZqNLBN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHyQA-RsNOXT"},"source":["### 5.5 Display plot of training and validation loss/accuracy wrt to epochs"]},{"cell_type":"code","metadata":{"id":"gC7Lb0eSNawO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ey7an7ukLxWB"},"source":["## 6. Conclusion and Interpretation"]},{"cell_type":"code","metadata":{"id":"3b2eLAk9NeNz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nwOCcvqxVCH"},"source":["## 7. Food for thought:\n","\n","1.) Change activation function (try leaky_relu or tanh) and see if it helps in improving model performance with the dataset that is highly imbalanced\n","\n","2.) Try with only the overall review feature and see if it leads to improvement in model performace\n","\n","3.) Change the hyperparameters of the model and compare the results "]},{"cell_type":"code","metadata":{"id":"VCylm4X8Nfik"},"source":[""],"execution_count":null,"outputs":[]}]}